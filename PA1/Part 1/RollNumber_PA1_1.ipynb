{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Part 1 Instructions **[50 marks]**\n",
    "\n",
    "## Overview\n",
    "You are required to develop a **Retrieval-Augmented Generation (RAG) system** from scratch. This includes implementing embeddings, storing them in a vector database, building a retriever, and chaining it with an LLM. You will then **experiment with retrieval parameters** and analyze their effects on system accuracy. A bonus section will allow you to refine the system with **prompt engineering**.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Build the RAG Chain (20 marks)\n",
    "\n",
    "### Requirements\n",
    "- Implement embeddings and store them in a **vector database**.  \n",
    "- Implement a retriever and build the **RAG chain** that connects it with an LLM.  \n",
    "- Ensure the pipeline can retrieve relevant chunks and generate answers.  \n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Chaining for Extended Context (10 marks)\n",
    "\n",
    "### Requirements\n",
    "- Implement **chaining** that allows the LLM to go beyond retrieved context.  \n",
    "- Demonstrate how chaining enables multi-step reasoning or broader context handling.  \n",
    "\n",
    "---\n",
    "\n",
    "## Part 3: Parameter Testing & Report (20 marks)\n",
    "\n",
    "### Requirements\n",
    "- Use the provided dataset of **20 questions** (10 with one-word answers, 10 with no answer).  \n",
    "- Explore different values for:  \n",
    "  - **Chunk size**  \n",
    "  - **Chunk overlap**  \n",
    "  - **Top-K retrieval**  \n",
    "  - **Similarity cutoff threshold**  \n",
    "- Record and analyze how parameter choices affect accuracy.  \n",
    "- Submit a **report** summarizing:  \n",
    "  - The results of your experiments.  \n",
    "  - Explanations of why certain parameters improved or degraded performance.  \n",
    "\n",
    "---\n",
    "\n",
    "## Bonus: Prompt Engineering (5+5 marks)\n",
    "\n",
    "### Requirements\n",
    "- Refine your system using **prompt engineering** so that:  \n",
    "  - For answerable questions → the LLM provides the correct answer.  \n",
    "  - For unanswerable questions → the LLM responds with *“I don’t know”*.  \n",
    "\n",
    "### Notes:\n",
    "- Bonus marks can be used to recover deductions from earlier parts.  \n",
    "- Creativity and clarity in prompt design will be rewarded.  \n",
    "- Do **not** use GPT or other AI tools to generate code. Instead, consult the documentation — learning to use these tools independently is essential for your course projects.  \n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation Criteria\n",
    "- **Correctness**: The RAG chain should work end-to-end.  \n",
    "- **Implementation**: Proper embeddings, vector DB, retriever, and chaining.  \n",
    "- **Analysis**: Depth of reasoning in your parameter exploration report.  \n",
    "- **Bonus (Optional)**: Effective prompt engineering to balance correctness and abstention.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "First, we install the required packages:\n",
    "\n",
    "- **LangChain** and **LangChain Community**: provide loaders, splitters, retrievers, etc.  \n",
    "- **LangChain HuggingFace**: for embedding models.  \n",
    "- **LangChain Pinecone** and **pinecone-client**: for vector database storage.  \n",
    "- **python-dotenv**: for managing API keys securely.  \n",
    "- **Streamlit**: (optional) for building a user interface.  \n",
    "- **MistralAI client**: for the language model we’ll use.\n",
    "\n",
    "This ensures our environment has all dependencies for building a RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.31-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.43-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.4-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.15-cp313-cp313-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=2.1.0 (from langchain-community)\n",
      "  Downloading numpy-2.3.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.4-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl.metadata (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.3-cp313-cp313-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.25.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 8.0 MB/s  0:00:00\n",
      "Downloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 25.3 MB/s  0:00:00\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 51.5 MB/s  0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 39.8 MB/s  0:00:00\n",
      "Downloading aiohttp-3.12.15-cp313-cp313-win_amd64.whl (449 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading langsmith-0.4.31-py3-none-any.whl (386 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.4-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Downloading greenlet-3.2.4-cp313-cp313-win_amd64.whl (299 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.3.3-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 7.3/12.8 MB 37.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.8 MB 25.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.8 MB 21.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 18.2 MB/s  0:00:00\n",
      "Downloading orjson-3.11.3-cp313-cp313-win_amd64.whl (131 kB)\n",
      "Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.25.0-cp313-cp313-win_amd64.whl (506 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-extensions, tenacity, sniffio, PyYAML, python-dotenv, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, idna, httpx-sse, h11, greenlet, frozenlist, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, typing-inspect, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, pydantic, httpx, dataclasses-json, aiohttp, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "\n",
      "    ---------------------------------------  1/45 [urllib3]\n",
      "    ---------------------------------------  1/45 [urllib3]\n",
      "    ---------------------------------------  1/45 [urllib3]\n",
      "    ---------------------------------------  1/45 [urllib3]\n",
      "   - --------------------------------------  2/45 [typing-extensions]\n",
      "   -- -------------------------------------  3/45 [tenacity]\n",
      "   --- ------------------------------------  4/45 [sniffio]\n",
      "   ---- -----------------------------------  5/45 [PyYAML]\n",
      "   ---- -----------------------------------  5/45 [PyYAML]\n",
      "   ----- ----------------------------------  6/45 [python-dotenv]\n",
      "   ------ ---------------------------------  7/45 [propcache]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   -------- -------------------------------  9/45 [numpy]\n",
      "   --------- ------------------------------ 11/45 [multidict]\n",
      "   ---------- ----------------------------- 12/45 [marshmallow]\n",
      "   ----------- ---------------------------- 13/45 [jsonpointer]\n",
      "   ------------ --------------------------- 14/45 [idna]\n",
      "   ------------- -------------------------- 15/45 [httpx-sse]\n",
      "   -------------- ------------------------- 16/45 [h11]\n",
      "   --------------- ------------------------ 17/45 [greenlet]\n",
      "   --------------- ------------------------ 17/45 [greenlet]\n",
      "   --------------- ------------------------ 17/45 [greenlet]\n",
      "   ---------------- ----------------------- 19/45 [charset_normalizer]\n",
      "   ---------------- ----------------------- 19/45 [charset_normalizer]\n",
      "   ------------------ --------------------- 21/45 [attrs]\n",
      "   ------------------ --------------------- 21/45 [attrs]\n",
      "   ------------------- -------------------- 22/45 [annotated-types]\n",
      "   --------------------- ------------------ 24/45 [yarl]\n",
      "   ----------------------- ---------------- 26/45 [typing-inspect]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 27/45 [SQLAlchemy]\n",
      "   ------------------------ --------------- 28/45 [requests]\n",
      "   ------------------------- -------------- 29/45 [pydantic-core]\n",
      "   -------------------------- ------------- 30/45 [jsonpatch]\n",
      "   --------------------------- ------------ 31/45 [httpcore]\n",
      "   --------------------------- ------------ 31/45 [httpcore]\n",
      "   --------------------------- ------------ 31/45 [httpcore]\n",
      "   ---------------------------- ----------- 32/45 [anyio]\n",
      "   ---------------------------- ----------- 32/45 [anyio]\n",
      "   ---------------------------- ----------- 32/45 [anyio]\n",
      "   ---------------------------- ----------- 32/45 [anyio]\n",
      "   ---------------------------- ----------- 32/45 [anyio]\n",
      "   ------------------------------ --------- 34/45 [requests-toolbelt]\n",
      "   ------------------------------ --------- 34/45 [requests-toolbelt]\n",
      "   ------------------------------ --------- 34/45 [requests-toolbelt]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   ------------------------------- -------- 35/45 [pydantic]\n",
      "   -------------------------------- ------- 36/45 [httpx]\n",
      "   -------------------------------- ------- 36/45 [httpx]\n",
      "   -------------------------------- ------- 36/45 [httpx]\n",
      "   -------------------------------- ------- 37/45 [dataclasses-json]\n",
      "   --------------------------------- ------ 38/45 [aiohttp]\n",
      "   --------------------------------- ------ 38/45 [aiohttp]\n",
      "   --------------------------------- ------ 38/45 [aiohttp]\n",
      "   --------------------------------- ------ 38/45 [aiohttp]\n",
      "   --------------------------------- ------ 38/45 [aiohttp]\n",
      "   --------------------------------- ------ 38/45 [aiohttp]\n",
      "   --------------------------------- ------ 38/45 [aiohttp]\n",
      "   ---------------------------------- ----- 39/45 [pydantic-settings]\n",
      "   ---------------------------------- ----- 39/45 [pydantic-settings]\n",
      "   ---------------------------------- ----- 39/45 [pydantic-settings]\n",
      "   ----------------------------------- ---- 40/45 [langsmith]\n",
      "   ----------------------------------- ---- 40/45 [langsmith]\n",
      "   ----------------------------------- ---- 40/45 [langsmith]\n",
      "   ----------------------------------- ---- 40/45 [langsmith]\n",
      "   ----------------------------------- ---- 40/45 [langsmith]\n",
      "   ----------------------------------- ---- 40/45 [langsmith]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------ --- 41/45 [langchain-core]\n",
      "   ------------------------------------- -- 42/45 [langchain-text-splitters]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   -------------------------------------- - 43/45 [langchain]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------  44/45 [langchain-community]\n",
      "   ---------------------------------------- 45/45 [langchain-community]\n",
      "\n",
      "Successfully installed PyYAML-6.0.3 SQLAlchemy-2.0.43 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 dataclasses-json-0.6.7 frozenlist-1.7.0 greenlet-3.2.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-community-0.3.30 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.4.31 marshmallow-3.26.1 multidict-6.6.4 mypy-extensions-1.1.0 numpy-2.3.3 orjson-3.11.3 propcache-0.3.2 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-settings-2.11.0 python-dotenv-1.1.1 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.1 urllib3-2.5.0 yarl-1.20.1 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.1.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-huggingface) (0.3.76)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting huggingface-hub>=0.33.4 (from langchain-huggingface)\n",
      "  Downloading huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Collecting filelock (from huggingface-hub>=0.33.4->langchain-huggingface)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.33.4->langchain-huggingface)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.33.4->langchain-huggingface)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.5.0)\n",
      "Requirement already satisfied: colorama in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.33.4->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n",
      "Downloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading pypdf-6.1.0-py3-none-any.whl (322 kB)\n",
      "Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
      "   ---------------------------------------- 0.0/563.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 563.3/563.3 kB 13.7 MB/s  0:00:00\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 24.9 MB/s  0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: tqdm, pypdf, fsspec, filelock, huggingface-hub, tokenizers, langchain-huggingface\n",
      "\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ----- ---------------------------------- 1/7 [pypdf]\n",
      "   ----- ---------------------------------- 1/7 [pypdf]\n",
      "   ----- ---------------------------------- 1/7 [pypdf]\n",
      "   ----- ---------------------------------- 1/7 [pypdf]\n",
      "   ----- ---------------------------------- 1/7 [pypdf]\n",
      "   ----- ---------------------------------- 1/7 [pypdf]\n",
      "   ----- ---------------------------------- 1/7 [pypdf]\n",
      "   ----- ---------------------------------- 1/7 [pypdf]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------------- ---------------------- 3/7 [filelock]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------------- ----------- 5/7 [tokenizers]\n",
      "   ---------------------------- ----------- 5/7 [tokenizers]\n",
      "   ---------------------------------- ----- 6/7 [langchain-huggingface]\n",
      "   ---------------------------------------- 7/7 [langchain-huggingface]\n",
      "\n",
      "Successfully installed filelock-3.19.1 fsspec-2025.9.0 huggingface-hub-0.35.1 langchain-huggingface-0.3.1 pypdf-6.1.0 tokenizers-0.22.1 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-pinecone\n",
      "  Downloading langchain_pinecone-0.2.12-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-pinecone) (0.3.76)\n",
      "Collecting pinecone<8.0.0,>=6.0.0 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy>=1.26.4 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-pinecone) (2.3.3)\n",
      "Collecting langchain-openai>=0.3.11 (from langchain-pinecone)\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: httpx>=0.28.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-pinecone) (0.28.1)\n",
      "Collecting simsimd>=5.9.11 (from langchain-pinecone)\n",
      "  Downloading simsimd-6.5.3-cp313-cp313-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.4.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.0.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2025.8.3)\n",
      "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.5.0)\n",
      "Collecting packaging>=23.2 (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.32.5)\n",
      "Requirement already satisfied: aiohttp>=3.9.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (3.12.15)\n",
      "Collecting aiohttp-retry<3.0.0,>=2.9.1 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (3.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.20.1)\n",
      "Requirement already satisfied: anyio in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from httpx>=0.28.0->langchain-pinecone) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from httpx>=0.28.0->langchain-pinecone) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.28.0->langchain-pinecone) (0.16.0)\n",
      "Collecting openai<2.0.0,>=1.104.2 (from langchain-openai>=0.3.11->langchain-pinecone)\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai>=0.3.11->langchain-pinecone)\n",
      "  Downloading tiktoken-0.11.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.104.2->langchain-openai>=0.3.11->langchain-pinecone)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.104.2->langchain-openai>=0.3.11->langchain-pinecone)\n",
      "  Downloading jiter-0.11.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai>=0.3.11->langchain-pinecone) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai>=0.3.11->langchain-pinecone) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.4.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai>=0.3.11->langchain-pinecone)\n",
      "  Downloading regex-2025.9.18-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.25.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\n",
      "Requirement already satisfied: colorama in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.104.2->langchain-openai>=0.3.11->langchain-pinecone) (0.4.6)\n",
      "Downloading langchain_pinecone-0.2.12-py3-none-any.whl (25 kB)\n",
      "Downloading pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
      "   ---------------------------------------- 0.0/587.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 587.6/587.6 kB 6.1 MB/s  0:00:00\n",
      "Downloading pinecone_plugin_assistant-1.8.0-py3-none-any.whl (259 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
      "Downloading pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\n",
      "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "   ---------------------------------------- 0.0/948.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 948.6/948.6 kB 14.5 MB/s  0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.11.0-cp313-cp313-win_amd64.whl (202 kB)\n",
      "Downloading tiktoken-0.11.0-cp313-cp313-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 883.9/883.9 kB 34.8 MB/s  0:00:00\n",
      "Downloading regex-2025.9.18-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Downloading simsimd-6.5.3-cp313-cp313-win_amd64.whl (94 kB)\n",
      "Installing collected packages: simsimd, regex, pinecone-plugin-interface, packaging, jiter, distro, tiktoken, pinecone-plugin-assistant, pinecone-client, pinecone, openai, aiohttp-retry, langchain-openai, langchain-pinecone\n",
      "\n",
      "   -- -------------------------------------  1/14 [regex]\n",
      "  Attempting uninstall: packaging\n",
      "   -- -------------------------------------  1/14 [regex]\n",
      "   -------- -------------------------------  3/14 [packaging]\n",
      "    Found existing installation: packaging 25.0\n",
      "   -------- -------------------------------  3/14 [packaging]\n",
      "    Uninstalling packaging-25.0:\n",
      "   -------- -------------------------------  3/14 [packaging]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   -------- -------------------------------  3/14 [packaging]\n",
      "   -------- -------------------------------  3/14 [packaging]\n",
      "   -------- -------------------------------  3/14 [packaging]\n",
      "   -------------- -------------------------  5/14 [distro]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   -------------------- -------------------  7/14 [pinecone-plugin-assistant]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ------------------------- --------------  9/14 [pinecone]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ---------------------------- ----------- 10/14 [openai]\n",
      "   ------------------------------- -------- 11/14 [aiohttp-retry]\n",
      "   ---------------------------------- ----- 12/14 [langchain-openai]\n",
      "   ---------------------------------- ----- 12/14 [langchain-openai]\n",
      "   ---------------------------------------- 14/14 [langchain-pinecone]\n",
      "\n",
      "Successfully installed aiohttp-retry-2.9.1 distro-1.9.0 jiter-0.11.0 langchain-openai-0.3.33 langchain-pinecone-0.2.12 openai-1.109.1 packaging-24.2 pinecone-7.3.0 pinecone-client-6.0.0 pinecone-plugin-assistant-1.8.0 pinecone-plugin-interface-0.0.7 regex-2025.9.18 simsimd-6.5.3 tiktoken-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (1.1.1)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from streamlit) (2.3.3)\n",
      "Requirement already satisfied: packaging<26,>=20 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from streamlit) (24.2)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
      "  Downloading pandas-2.3.2-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<12,>=7.1.0 (from streamlit)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<7,>=3.20 (from streamlit)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from streamlit) (6.5.2)\n",
      "Collecting jinja2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\coding\\cs_6303\\pa1\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 3.7/10.1 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.1 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 18.4 MB/s  0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 731.2/731.2 kB 39.3 MB/s  0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pandas-2.3.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 5.0/11.0 MB 26.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 25.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 22.5 MB/s  0:00:00\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 59.2 MB/s  0:00:00\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 3.7/6.9 MB 19.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.9 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 14.7 MB/s  0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading narwhals-2.5.0-py3-none-any.whl (407 kB)\n",
      "Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "   ---------------------------------------- 0.0/26.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 8.7/26.1 MB 65.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.1/26.1 MB 29.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.7/26.1 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.8/26.1 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.2/26.1 MB 19.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.5/26.1 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.2/26.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.1/26.1 MB 15.7 MB/s  0:00:01\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl (232 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, watchdog, tzdata, toml, smmap, rpds-py, pyarrow, protobuf, pillow, narwhals, MarkupSafe, click, cachetools, blinker, referencing, pandas, jinja2, gitdb, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\n",
      "   ----------------------------------------  0/24 [pytz]\n",
      "   ----------------------------------------  0/24 [pytz]\n",
      "   ----------------------------------------  0/24 [pytz]\n",
      "   - --------------------------------------  1/24 [watchdog]\n",
      "   - --------------------------------------  1/24 [watchdog]\n",
      "   - --------------------------------------  1/24 [watchdog]\n",
      "   --- ------------------------------------  2/24 [tzdata]\n",
      "   --- ------------------------------------  2/24 [tzdata]\n",
      "   --- ------------------------------------  2/24 [tzdata]\n",
      "   ----- ----------------------------------  3/24 [toml]\n",
      "   ------ ---------------------------------  4/24 [smmap]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ----------- ----------------------------  7/24 [protobuf]\n",
      "   ----------- ----------------------------  7/24 [protobuf]\n",
      "   ----------- ----------------------------  7/24 [protobuf]\n",
      "   ----------- ----------------------------  7/24 [protobuf]\n",
      "   ----------- ----------------------------  7/24 [protobuf]\n",
      "   ----------- ----------------------------  7/24 [protobuf]\n",
      "   ----------- ----------------------------  7/24 [protobuf]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   ------------- --------------------------  8/24 [pillow]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   --------------- ------------------------  9/24 [narwhals]\n",
      "   ------------------ --------------------- 11/24 [click]\n",
      "   ------------------ --------------------- 11/24 [click]\n",
      "   ------------------ --------------------- 11/24 [click]\n",
      "   ----------------------- ---------------- 14/24 [referencing]\n",
      "   ----------------------- ---------------- 14/24 [referencing]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   ------------------------- -------------- 15/24 [pandas]\n",
      "   -------------------------- ------------- 16/24 [jinja2]\n",
      "   -------------------------- ------------- 16/24 [jinja2]\n",
      "   -------------------------- ------------- 16/24 [jinja2]\n",
      "   -------------------------- ------------- 16/24 [jinja2]\n",
      "   ---------------------------- ----------- 17/24 [gitdb]\n",
      "   ---------------------------- ----------- 17/24 [gitdb]\n",
      "   ------------------------------ --------- 18/24 [pydeck]\n",
      "   ------------------------------ --------- 18/24 [pydeck]\n",
      "   ------------------------------ --------- 18/24 [pydeck]\n",
      "   ------------------------------ --------- 18/24 [pydeck]\n",
      "   --------------------------------- ------ 20/24 [gitpython]\n",
      "   --------------------------------- ------ 20/24 [gitpython]\n",
      "   --------------------------------- ------ 20/24 [gitpython]\n",
      "   --------------------------------- ------ 20/24 [gitpython]\n",
      "   --------------------------------- ------ 20/24 [gitpython]\n",
      "   ----------------------------------- ---- 21/24 [jsonschema]\n",
      "   ----------------------------------- ---- 21/24 [jsonschema]\n",
      "   ----------------------------------- ---- 21/24 [jsonschema]\n",
      "   ----------------------------------- ---- 21/24 [jsonschema]\n",
      "   ------------------------------------ --- 22/24 [altair]\n",
      "   ------------------------------------ --- 22/24 [altair]\n",
      "   ------------------------------------ --- 22/24 [altair]\n",
      "   ------------------------------------ --- 22/24 [altair]\n",
      "   ------------------------------------ --- 22/24 [altair]\n",
      "   ------------------------------------ --- 22/24 [altair]\n",
      "   ------------------------------------ --- 22/24 [altair]\n",
      "   ------------------------------------ --- 22/24 [altair]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   -------------------------------------- - 23/24 [streamlit]\n",
      "   ---------------------------------------- 24/24 [streamlit]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 altair-5.5.0 blinker-1.9.0 cachetools-6.2.0 click-8.3.0 gitdb-4.0.12 gitpython-3.1.45 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 narwhals-2.5.0 pandas-2.3.2 pillow-11.3.0 protobuf-6.32.1 pyarrow-21.0.0 pydeck-0.9.1 pytz-2025.2 referencing-0.36.2 rpds-py-0.27.1 smmap-5.0.2 streamlit-1.50.0 toml-0.10.2 tzdata-2025.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community\n",
    "%pip install langchain-huggingface pypdf\n",
    "%pip install langchain-pinecone pinecone-client\n",
    "%pip install python-dotenv streamlit\n",
    "%pip install -qU langchain-mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\CS_6303\\PA1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\coding\\CS_6303\\PA1\\.venv\\Lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter as RCTS\n",
    "from langchain_mistralai import ChatMistralAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: RAG Chatbot  <span style=\"color:green\">**[20 marks]**</span>\n",
    "\n",
    "For guidance, you may refer to the following resources:  \n",
    "- [RAG Overview](https://python.langchain.com/docs/tutorials/rag/#overview)  \n",
    "- [How-to Guides](https://python.langchain.com/docs/how_to/)  \n",
    "- [Concepts](https://python.langchain.com/docs/concepts/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting API Keys\n",
    "\n",
    "We need API keys for external services:\n",
    "- [HuggingFace](https://huggingface.co/settings/tokens) (for embeddings)\n",
    "- [Pinecone](https://app.pinecone.io/) (for vector storage)\n",
    "- [MistralAI](https://console.mistral.ai/api-keys) (for the chat model)\n",
    "\n",
    "Here we define them as variables. Later we’ll store them securely using environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables are saved to .env file.\n"
     ]
    }
   ],
   "source": [
    "# You only need to run this cell once to create the .env file with your API keys.\n",
    "\n",
    "HUGGINGFACE_API_KEY = \"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\"  # Replace with your Hugging Face API key\n",
    "PINECONE_API_KEY = \"pcsk_6ZtTkA_Eia2MLVVms9XRXDHu8vwaiA7Dq9snWvEEkxC8crsPmKGUxgH36cx6xfynJqQRQS\"        # Replace with your Pinecone API key\n",
    "MISTRALAI_API_KEY = \"qmHaQqUteiIw2TGjzhqGfql7NkozZDBu\"       # Replace with your Mistral AI API key\n",
    "\n",
    "env_content = f\"\"\"\n",
    "HUGGINGFACE_API_KEY={HUGGINGFACE_API_KEY}\n",
    "PINECONE_API_KEY={PINECONE_API_KEY}\n",
    "MISTRALAI_API_KEY={MISTRALAI_API_KEY}\n",
    "\"\"\"\n",
    "\n",
    "with open(\".env\", \"w\") as file:\n",
    "    file.write(env_content)\n",
    "\n",
    "print(\"Environment variables are saved to .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Environment Variables\n",
    "\n",
    "We use `dotenv` to manage keys.  \n",
    "Instead of hardcoding secrets, we load them from a `.env` file.  \n",
    "This keeps our notebook secure and avoids accidentally sharing keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Splitting Documents\n",
    "\n",
    "Our knowledge source is a **PDF document** (the Undergraduate Student Handbook).  \n",
    "Steps:\n",
    "1. Load the PDF using `PyPDFLoader`.  \n",
    "2. Split the text into smaller chunks using `RecursiveCharacterTextSplitter`.  \n",
    "\n",
    "Why split?  \n",
    "- Large text doesn’t fit into the LLM’s context window.  \n",
    "- Smaller chunks make retrieval more accurate during question-answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './Undergraduate Student Handbook 2021-2022.pdf'\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 4\n",
    "\n",
    "text_splitter = RCTS(chunk_size=chunk_size, chunk_overlap=chunk_overlap, add_start_index=True)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Initialize Pinecone and Create a Vector Store\n",
    "\n",
    "Your task is to **set up Pinecone** as the vector database for this RAG system.  \n",
    "\n",
    "#### Requirements:  \n",
    "- If the index with the given name already exists, reuse it. Otherwise, **create a new index**.  \n",
    "- Use the following configuration for the index:\n",
    "  - **Dimension:** 768  \n",
    "  - **Metric:** cosine similarity  \n",
    "  - **Cloud:** AWS, region `us-east-1`  \n",
    "- Initialize the **embedding model** (`HuggingFaceEmbeddings`).  \n",
    "- Return a **`PineconeVectorStore`** object.  \n",
    "\n",
    "> 💡 *Hint:* Make sure you return the vector store at the end of the function so it can be used later in your RAG pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_pinecone(pc, index_name):\n",
    "    # TODO: Check if index_name already exists, otherwise create it\n",
    "    # - Use dimension=768\n",
    "    # - Metric=\"cosine\"\n",
    "    # - Cloud=\"aws\"\n",
    "    # - Region=\"us-east-1\"\n",
    "\n",
    "    existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "    if index_name not in existing_indexes:\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=768,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "        )\n",
    "\n",
    "    # TODO: Initialize embeddings model (default)\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings()  # Use CPU for embeddings\n",
    "\n",
    "    # TODO: Load the index and initialize the PineconeVectorStore\n",
    "    index = pc.Index(index_name)\n",
    "    vector_store = PineconeVectorStore(index=index, embedding=embeddings) \n",
    "\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Add Documents to Pinecone\n",
    "\n",
    "Your task is to **add documents to the Pinecone vector store**.  \n",
    "\n",
    "#### Requirements:\n",
    "- Each document must be assigned a **unique ID** before insertion.  \n",
    "- Use `uuid4()` to generate IDs for all documents.  \n",
    "- Add the provided list of texts to the given **vector store**.  \n",
    "- Ensure the function returns nothing but successfully inserts the documents.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_documents_to_pinecone(documents, vector_store):\n",
    "    # TODO: Generate a unique ID for each text using uuid4\n",
    "    uuids = [str(uuid4()) for _ in range(len(documents))]  \n",
    "\n",
    "    # TODO: Add texts and their IDs to the vector store\n",
    "    vector_store.add_texts(texts=[doc.page_content for doc in documents], ids=uuids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Create a Retriever from Vector Store\n",
    "\n",
    "Your task is to **create a retriever** that will query the vector store for the most relevant documents.  \n",
    "\n",
    "#### Requirements:\n",
    "- Convert the `vector_store` into a retriever using `.as_retriever()`.  \n",
    "- Use **similarity with score threshold** as the search type.  \n",
    "- The retriever should take two parameters:  \n",
    "  - **top_k** → maximum number of documents to retrieve.  \n",
    "  - **score_threshold** → minimum similarity score required for retrieval.  \n",
    "- Return the retriever object.  \n",
    "\n",
    "> 💡 *Hint:* Adjusting `top_k` and `score_threshold` will be important later when you experiment with retrieval performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever(vector_store, top_k=2, score_threshold=0.5):\n",
    "    # TODO: Create a retriever using similarity with score threshold\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": top_k, \"score_threshold\": score_threshold})  \n",
    "\n",
    "    return retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a Simple Similarity Search\n",
    "\n",
    "Now that you have implemented the helper functions, it’s time to test the full retrieval pipeline.\n",
    "\n",
    "#### Steps:\n",
    "1. Initialize Pinecone using your API key (`PINECONE_API_KEY`) and then a vector store.  \n",
    "2. Add handbook documents to the vector store using `add_documents_to_pinecone()`.  \n",
    "3. Run a **similarity search** against the vector store with a query (e.g., *\"Grading Policy\"*).  \n",
    "4. Retrieve the top `k` chunks and print out their content and metadata.  \n",
    "\n",
    "> 💡 *Hint:* This step ensures that your embeddings and vector store are working correctly before moving on to building the RAG chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GNG\\AppData\\Local\\Temp\\ipykernel_7400\\1127639835.py:20: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()  # Use CPU for embeddings\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize Pinecone and create/reuse vector store\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "vector_store = initialize_pinecone(pc, index_name=\"handbook\")\n",
    "\n",
    "# Step 2: we will use the previously created `docs` variable\n",
    "add_documents_to_pinecone(docs, vector_store)\n",
    "\n",
    "# Step 3: Initialize retriever\n",
    "k = 2\n",
    "threshold = 0.5\n",
    "retriever = create_retriever(vector_store, top_k=k, score_threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* The instructor informs students about the weightage\n",
      " \n",
      "assigned to each instrument. This is men\u0000oned in the \n",
      "course outline, and it is used for evalua\u0000ng student performance in the course.\n",
      " \n",
      "21.2.\n",
      " \n",
      "Grading Policy\n",
      " \n",
      "Course grades are based on cumula\u0000ve performance in deﬁned instruments. \n",
      " \n",
      " \n",
      "The ﬁnal grades are assigned as follows:\n",
      " \n",
      " \n",
      "Table 2\n",
      "  \n",
      "Le\u0000er Grades and their Numeric Equivalents\n",
      " \n",
      " \n",
      " \n",
      " LETTER GRADE\n",
      " \n",
      "NUMERIC EQUIVALENT\n",
      " \n",
      "Excep\u0000onal\n",
      " \n",
      "A+\n",
      " \n",
      "4.0\n",
      " \n",
      "Outstanding\n",
      " \n",
      "A\n",
      " \n",
      "4.0\n",
      " \n",
      "Excellent\n",
      " \n",
      "A-\n",
      " \n",
      "3.7\n",
      " \n",
      "Very Good\n",
      " \n",
      "B+\n",
      " \n",
      "3.3\n",
      " \n",
      "Good\n",
      " \n",
      "B\n",
      " \n",
      "3.0\n",
      " \n",
      "Average\n",
      " \n",
      "B-\n",
      " \n",
      "2.7\n",
      " \n",
      "Sa\u0000sfactory\n",
      " \n",
      "C+\n",
      " \n",
      "2.3\n",
      " \n",
      "Low Pass C  2.0  \n",
      "Marginal Pass C-  1.7  \n",
      "Unsa\u0000sfactory D  1.0  \n",
      "Pass *P  -  \n",
      "Fail F  0.0  \n",
      "Withdrawn **W  -  Incomplete \n",
      " \n",
      "***I\n",
      " \n",
      "-\n",
      " Transfer\n",
      " \n",
      "****T\n",
      " \n",
      "-\n",
      " \n",
      " Grading at LUMS is based on rela \u0000ve performance. However, for some courses, absolute grading is used. This \n",
      "informa\u0000on is men\u0000oned in the course outline.\n",
      " \n",
      "A+\n",
      " \n",
      "and F\n",
      " \n",
      "are absolute grades. The other grades (A [{}]\n",
      "* review the grade change request.\n",
      " \n",
      " \n",
      "21.7.\n",
      " \n",
      "Course Pass/Fail Policy\n",
      " \n",
      "The purpose of the course Pass/Fail policy is to provide students with the opportunity to take courses of \n",
      "interest outside of their major ﬁeld of study and to learn without concern for the grade havin g an impact \n",
      "on their GPA. This policy encourages learning diversity and provides students, who have not decided upon \n",
      "a major, the opportunity to explore diﬀerent areas of study.\n",
      " \n",
      " \n",
      "The important points regarding this policy are: \n",
      "· It is the preroga\u0000ve of ind ividual instructors as to whether they wish to allow their course to be \n",
      "taken as Pass/Fail. The student should only proceed to apply for Pass/Fail for a course if the \n",
      "instructor agrees.  \n",
      "· First year students in their ﬁrst semester are excluded from this policy.  \n",
      "· A student can choose to designate a course as Pass/Fail \u0000ll the same date as the Drop Only deadline  ·\n",
      " \n",
      "Pass/Fail courses can only count towards the free elec\u0000ves’\n",
      " \n",
      "requirement. \n",
      " · [{}]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Perform a similarity search with a query\n",
    "results = retriever.get_relevant_documents(\"Grading Policy\")\n",
    "\n",
    "# Step 5: Print out the content and metadata of the retrieved results\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Chat Model (Mistral AI)\n",
    "\n",
    "We now set up the **LLM** that will generate answers.  \n",
    "Here we initialize the **[Mistral model](https://docs.mistral.ai/getting-started/models/models_overview/)** using our API key.  \n",
    "\n",
    "This model will take the retrieved handbook text + user question, and generate a clear answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = \"ministral-3b-latest\"\n",
    "llm = ChatMistralAI(\n",
    "    model=model,\n",
    "    temperature=0,\n",
    "    max_retries=1,\n",
    "    api_key=os.getenv(\"MISTRALAI_API_KEY\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Prompt Template\n",
    "\n",
    "Language models work best when guided with **clear instructions**.  \n",
    "Here we create a **PromptTemplate** that tells the chatbot exactly how to behave:\n",
    "\n",
    "- It is designed to answer questions **only about the LUMS Student Handbook**.  \n",
    "- It must use the **given context** (retrieved chunks from the handbook).  \n",
    "- If the answer is not in the context, it should respond with **“I don’t know”**.  \n",
    "- The template takes two inputs:  \n",
    "  1. **context** – text retrieved from the handbook.  \n",
    "  2. **question** – the student’s query.  \n",
    "\n",
    "This ensures the chatbot gives reliable answers and avoids making things up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the modified prompt template\n",
    "template = \"\"\"\n",
    "You are a chatbot designed to answer questions from LUMS students. LUMS is a university and you have access to the student handbook.\n",
    "Use following extract from the handbook to answer the question.\n",
    "If the context doesn't contain any relevant information to the question, then just say \"I don't know\".\n",
    "If you don't know the answer, then just say \"I don't know\".\n",
    "Do NOT make something up.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RAG Chain\n",
    "\n",
    "Now that you have a retriever & LLM, it’s time to connect both with a **prompt template** to form the RAG pipeline.\n",
    "\n",
    "### Requirements:\n",
    "- Take in three inputs:\n",
    "  - **retriever** → to fetch relevant context from the vector store.  \n",
    "  - **prompt** → the prompt template that structures inputs for the LLM.  \n",
    "  - **llm** → the language model used for generation.  \n",
    "- Chain the components together in the following order:\n",
    "  1. Retrieve documents (`retriever | format_docs`).  \n",
    "  2. Pass context and the user question into the **prompt**.  \n",
    "  3. Send the formatted prompt to the **LLM**.  \n",
    "  4. Parse the response into a clean string (`StrOutputParser`).  \n",
    "- Return the completed RAG chain object.  \n",
    "\n",
    "> 💡 *Hint:* This chain will be the foundation for answering user queries with retrieved context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):  # stitches together retrieved documents\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "def build_rag_chain(retriever, prompt, llm):\n",
    "    # TODO: Combine retriever, prompt, and llm into a chain\n",
    "    rag_chain = (\n",
    "        # 1. Retrieve docs and format them\n",
    "        {\"context\": retriever | format_docs,\n",
    "         \"question\": RunnablePassthrough()} # using runnable pass through to pass the question as is (from the .invoke)\n",
    "        # 2. Fill prompt with context + question\n",
    "        | prompt\n",
    "        # 3. Send to LLM\n",
    "        | llm\n",
    "        # 4. Parse clean string output\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_chain\n",
    "\n",
    "rag_chain = build_rag_chain(retriever, prompt, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Test the RAG Chain\n",
    "\n",
    "Now that your RAG chain is built, it’s time to **run a query** and inspect the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grading policy for LUMS is based on cumulative performance in defined instruments. The final grades are assigned as follows:\n",
      "\n",
      "- A+ (4.0)\n",
      "- A (4.0)\n",
      "- A- (3.7)\n",
      "- B+ (3.3)\n",
      "- B (3.0)\n",
      "- B- (2.7)\n",
      "- C+ (2.3)\n",
      "- Low Pass C (2.0)\n",
      "- Marginal Pass C- (1.7)\n",
      "- Unacceptable D (1.0)\n",
      "- Pass (P) (0.0)\n",
      "- Fail (F) (0.0)\n",
      "- Withdrawn (W) (0.0)\n",
      "- Incomplete (I) (0.0)\n",
      "- Transfer (T) (0.0)\n",
      "\n",
      "Grading at LUMS is based on relative performance, but for some courses, absolute grading is used. This information is mentioned in the course outline.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the grading policy for the university?\"\n",
    "result = rag_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minors offered at SBASSE include Biology, Chemistry, Computer Science, Mathematics, and Physics.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are some minors offered at SBASSE?\"\n",
    "result = rag_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Testing its limitations\n",
    "\n",
    "General questions that are not related to the university would not answered due to the way we structured the prompt template. Try asking such questions below to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are some gift ideas for Mothers Day?\"\n",
    "result = rag_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the fastest growing plant?\"\n",
    "result = rag_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Dynamic Routing <span style=\"color:green\">**[10 marks]**</span>\n",
    "\n",
    "One of the key advantages of LangChain is the ability to create **non-deterministic chains**, where the output of one step determines the next.  \n",
    "\n",
    "In this section, you will:\n",
    "1. **Build a classifier chain** to decide whether a user question is about *education/academic policies* or *Other*. [5 marks]  \n",
    "2. **Build a general LLM chain** that handles non-policy queries. [5 marks]  \n",
    "3. **Implement routing logic** that uses the classifier output to decide whether to send the query to the **RAG chain** (for policy-related questions) or to the **general chain** (for everything else). [10 marks]  \n",
    "\n",
    "#### Requirements:\n",
    "- Use a **prompt template** for classification (must only return `\"education/academic policies\"` or `\"Other\"`).  \n",
    "- Build a **general chain** that simply responds directly to a user’s query.  \n",
    "- Implement a `route()` function that:  \n",
    "  - Sends questions about education/academic policies → `rag_chain`.  \n",
    "  - Sends all other questions → `general_chain`.  \n",
    "- Combine everything into a `full_chain` that takes a question and automatically routes it.  \n",
    "\n",
    "> 💡 *Hint:* Use `RunnableLambda` for your routing logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example prompts for classification and general QA\n",
    "\n",
    "classifier_template = \"\"\"Given the user question below, classify it as either being about `education/academic policies`, or `Other`.\n",
    "\n",
    "Do not respond with anything other than 'education/academic policies' or 'Other'.\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\"\n",
    "\n",
    "general_template = \"\"\"Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the classifier chain\n",
    "classifier_prompt = None  # TODO: Build a PromptTemplate\n",
    "classifier_chain = None   # TODO: Build the classifier chain with RunnablePassthrough, classifier_prompt, llm, and StrOutputParser\n",
    "\n",
    "\n",
    "# 2. Define the general LLM chain\n",
    "general_prompt = None  # TODO: Build a PromptTemplate\n",
    "general_chain = None   # TODO: Build the general chain with RunnablePassthrough, general_prompt, llm, and StrOutputParser\n",
    "\n",
    "\n",
    "# 3. Implement routing logic \n",
    "def route(info):\n",
    "    # TODO: Implement routing logic based on the topic\n",
    "    pass\n",
    "\n",
    "# Combine into the full chain\n",
    "full_chain = None  # TODO: Combine classifier_chain, question passthrough, and routing logic into a full chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Our Improved ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the grading policy for the university?\"\n",
    "answer = full_chain.invoke({\"question\": question})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the biggest mammal?\"\n",
    "answer = full_chain.invoke({\"question\": question})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Experiment with Retrieval Parameters <span style=\"color:green\">**[20 marks]**</span>\n",
    "\n",
    "In this task, you will experiment with different parameter values to analyze their impact on model efficiency. Focus on **understanding how** changes in these parameters affect the results, not just aiming for the best accuracy.\n",
    "\n",
    "#### Parameters to Experiment With:\n",
    "- **Chunk Size**: `200, 300, 400, 600`\n",
    "- **Chunk Overlap**: `100, 200`\n",
    "- **Top K**: `1, 2, 3`\n",
    "- **Thresholds**: `0.3, 0.5, 0.7`\n",
    "\n",
    "Feel free to explore additional values within similar ranges, but keep consistent gaps between values. Test **at least 3 values** for each parameter (5 for better results).\n",
    "\n",
    "#### Deliverables:\n",
    "- **Report**: Summarize your findings in a report, including:\n",
    "  - **Tables** for results\n",
    "  - **Graphs** for visual representation\n",
    "  - **Explanations** of trends observed and why they occur.\n",
    "  \n",
    "  *The report should explain why the chosen ranges make sense and provide insights into your findings.*\n",
    "\n",
    "- **Code**: Include the code you used to generate the graphs below each corresponding cell for reproducibility.\n",
    "\n",
    "#### Evaluation Criteria:\n",
    "- **Ranges and Explanations**: Marks are based on the **quality of your chosen ranges** and the **clarity of your explanations**. \n",
    "  - For example, simply choosing the highest chunk size and achieving 1 accuracy in all cases is not the correct approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "1. Previously, you worked with documents extracted from a PDF. In this section, you will use a **CSV file** as the data source. \n",
    "2. Since the Pinecone free tier allows a maximum of **5 indexes**, we need a function to automatically delete the **least-used index** when this limit is reached.\n",
    "3. Also some helper functions for logging and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the modified prompt template\n",
    "template = \"\"\"\n",
    "You are a chatbot that can only provide answers based on the following provided context. \n",
    "Only use the context below to answer the question.\n",
    "If the context doesn't provide any information to answer the question, say \"I don't know\".\n",
    "Provide a brief, one-word answer if possible.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Function to split context into chunks with overlap\n",
    "def split_text_into_chunks(text, chunk_size=500, overlap=50):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunk = text[i:i + chunk_size]\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "# Function to add documents to Pinecone\n",
    "def add_text_to_pinecone(texts, vector_store):\n",
    "    uuids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    vector_store.add_texts(texts=texts, ids=uuids)\n",
    "\n",
    "# Function to delete index (you can do manually from Pinecone website as well) (you can change it to not delete handbook index)\n",
    "def delete_least_used_index(pc):\n",
    "    indexes = pc.list_indexes().names()\n",
    "\n",
    "    if len(indexes) >= 5:\n",
    "        index_to_delete = indexes[-1]\n",
    "        pc.delete_index(index_to_delete)\n",
    "        print(f\"Deleted least-used index: {index_to_delete}\")\n",
    "\n",
    "# Function to evaluate a question's response\n",
    "def evaluate_answer(predicted_answer, true_answer):    \n",
    "    # Compare the predicted answer with the true answer (case insensitive, and strip spaces)\n",
    "    predicted_answer = predicted_answer.strip().lower()\n",
    "    true_answer = true_answer.strip().lower()\n",
    "\n",
    "    return predicted_answer == true_answer\n",
    "\n",
    "# Function to log conversations and results to a text file\n",
    "def log_conversation_to_file(filename, chunk_size, overlap, top_k, question, context, predicted_answer, true_answer):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(f\"Chunk Size: {chunk_size}, Overlap: {overlap}, Top K: {top_k}\\n\")\n",
    "        f.write(f\"Context: {context}\\n\")\n",
    "        f.write(f\"Question: {question}\\n\")\n",
    "        f.write(f\"Predicted Answer: {predicted_answer}\\n\")\n",
    "        f.write(f\"True Answer: {true_answer}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step: Prepare Vector Store for a Dataset\n",
    "\n",
    "For each `(chunk_size, overlap)` pair, you need to:\n",
    "1. Initialize Pinecone and create/reuse an index.  \n",
    "2. Split dataset contexts into chunks.  \n",
    "3. Upload all chunks to the vector DB.  \n",
    "4. Call your `delete_least_used_index()` if needed.  \n",
    "\n",
    "This function ensures you only upload chunks **once per chunking configuration**, saving time during experiments.\n",
    "\n",
    "<span style=\"color:red\">!!! <span style=\"color:white\">why not take top k and threshold into consideration at this point? (add answer to your report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vector_store(dataset, chunk_size=500, overlap=50):\n",
    "    # Initialize Pinecone\n",
    "    pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "    index_name = f\"test-{chunk_size}-{overlap}\"\n",
    "    \n",
    "    # Create/reuse vector store\n",
    "    try:\n",
    "        vector_store = initialize_pinecone(pc, index_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Pinecone: {e}, returning\")\n",
    "        delete_least_used_index(pc)\n",
    "        try:\n",
    "            vector_store = initialize_pinecone(pc, index_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Second attempt failed: {e}, exiting\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "    all_chunks = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        context = row[\"context\"]\n",
    "        chunks = split_text_into_chunks(context, chunk_size=chunk_size, overlap=overlap)\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    add_text_to_pinecone(all_chunks, vector_store)\n",
    "\n",
    "    print(f\"Added {len(all_chunks)} chunks to {index_name}.\")\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step: Test a Single Question\n",
    "\n",
    "We define a helper function to run a single question through the RAG chain.\n",
    "\n",
    "#### Requirements:\n",
    "- Input: `question`, `chain`.  \n",
    "- Output: model’s predicted answer string.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_question(question, chain):\n",
    "    predicted_answer = chain.invoke(question)\n",
    "    return predicted_answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step: Complete Run \n",
    "A helper function to run a complete test with the given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_rag(dataset, chunk_sizes, overlaps, top_k_values, thresholds, test_prompt=prompt, llm=llm, exp_name=\"log\"):\n",
    "    results = []\n",
    "\n",
    "    for chunk_size in chunk_sizes:\n",
    "        for overlap in overlaps:\n",
    "            vector_store = prepare_vector_store(dataset, chunk_size, overlap)\n",
    "\n",
    "            for top_k in top_k_values:\n",
    "                for threshold in thresholds:\n",
    "                    retriever = create_retriever(vector_store, top_k=top_k, score_threshold=threshold)\n",
    "                    test_chain = build_rag_chain(retriever, test_prompt, llm)\n",
    "                    filename = exp_name + f\"_cs{chunk_size}_ov{overlap}_k{top_k}_th{threshold}.txt\"\n",
    "\n",
    "                    correct, total = 0, 0\n",
    "                    for _, row in dataset.iterrows():\n",
    "                        question = row[\"question\"]\n",
    "                        context = row[\"context\"]\n",
    "                        true_answer_dict = eval(row[\"answers\"])\n",
    "                        true_answer = true_answer_dict['text'][0] if true_answer_dict['text'] else \"I don't know\"\n",
    "\n",
    "                        predicted = test_question(question, test_chain)\n",
    "\n",
    "                        log_conversation_to_file(filename, chunk_size, overlap, top_k, question, context, predicted, true_answer)\n",
    "                        if evaluate_answer(predicted, true_answer):\n",
    "                            correct += 1\n",
    "                        total += 1\n",
    "\n",
    "                    accuracy = correct / total if total > 0 else 0\n",
    "                    results.append({\n",
    "                        \"chunk_size\": chunk_size,\n",
    "                        \"overlap\": overlap,\n",
    "                        \"top_k\": top_k,\n",
    "                        \"threshold\": threshold,\n",
    "                        \"accuracy\": accuracy\n",
    "                    })\n",
    "\n",
    "                    print(f\"cs={chunk_size}, ov={overlap}, k={top_k}, th={threshold} → Acc={accuracy:.4f}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Run Experiments on Dataset Splits\n",
    "\n",
    "We will now use the `experiment_rag()` function to test different parameter combinations.  \n",
    "\n",
    "#### Requirements:\n",
    "1. Load the dataset from CSV.  \n",
    "2. Split it into two halves:  \n",
    "   - **d1** → first 10 rows (e.g., answerable questions).  \n",
    "   - **d2** → last 10 rows (e.g., unanswerable questions).  \n",
    "3. Run `experiment_rag()` separately on each split.  \n",
    "4. Compare the results for **d1** vs **d2**.  \n",
    "\n",
    "> 💡 *Hint:* Choose a few values for `chunk_sizes`, `overlaps`, `top_k_values`, and `thresholds` so the experiments run in reasonable time.\n",
    "\n",
    "#### Primary Focus:\n",
    "- The **primary rows of interest** are the 10 rows in **d1** (answerable questions).  \n",
    "- Improvements seen in **d2** can likely be attributed to prompt engineering, which can be explored further in the bonus section.\n",
    "\n",
    "#### Reporting:\n",
    "- In your report, place more emphasis on the **d1 subset** of the dataset, as it is the key focus of this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load dataset\n",
    "dataset = load_dataset(\"test_subset.csv\")\n",
    "\n",
    "# Step 2: Split dataset into two parts\n",
    "d1 = dataset.head(10)  # First 10 rows\n",
    "d2 = dataset.tail(10)  # Last 10 rows\n",
    "\n",
    "# Step 3: Define parameter values to test\n",
    "chunk_sizes = [200, 400]          # TODO: Adjust as needed\n",
    "overlaps = [50, 100]              # TODO: Adjust as needed\n",
    "top_k_values = [2, 3]             # TODO: Adjust as needed\n",
    "thresholds = [0.3, 0.5, 0.7]      # TODO: Adjust as needed\n",
    "\n",
    "# Step 4: Run experiments on each subset\n",
    "print(\"### Results on d1 (first 10 rows) ###\")\n",
    "results_d1 = experiment_rag(d1, chunk_sizes, overlaps, top_k_values, thresholds, exp_name=\"d1\")\n",
    "\n",
    "print(\"\\n### Results on d2 (last 10 rows) ###\")\n",
    "results_d2 = experiment_rag(d2, chunk_sizes, overlaps, top_k_values, thresholds, exp_name=\"d2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Part: Prompt Engineering <span style=\"color:green\">**[10 marks]**</span> \n",
    "\n",
    "\n",
    "In this part, your task is to **enhance the prompt** used in the previous experiments by applying prompt engineering techniques to improve the performance.\n",
    "\n",
    "#### Requirements:\n",
    "1. **Improve the Prompt**: Apply prompt engineering techniques to create a more effective and generalized prompt.  \n",
    "2. **Report Addition**: Extend your report from the previous part to include:\n",
    "   - How you came up with the improved prompt.\n",
    "   - Why you believe the new prompt performs better than the provided prompt.\n",
    "   - A comparison of the results (accuracy) between the original and improved prompt, focusing on **d2** (unanswerable questions).\n",
    "\n",
    "#### Key Objectives:\n",
    "- **Performance Tuning**: The goal is **not** to achieve the best accuracy but to **optimize performance** through prompt engineering.\n",
    "- **Generalization**: Ensure that the improved prompt works for both **answerable (d1)** and **unanswerable (d2)** questions, maintaining a balance in performance across both subsets. Your prompt should not only excel in **d2** but also maintain good performance in **d1**.\n",
    "\n",
    "In your report, provide an explanation of the trade-offs made during prompt engineering and how it influences the results in both subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_template = \"\"\"Respond to the following question:\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "improved_prompt = PromptTemplate(template=improved_template, input_variables=[\"question\"])\n",
    "\n",
    "# improved_chain = build_rag_chain(retriever, improved_prompt, llm) #(for manual testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Results on d1 (first 10 rows) ###\")\n",
    "results_d1 = experiment_rag(d1, chunk_sizes, overlaps, top_k_values, thresholds, test_prompt=improved_prompt, exp_name=\"bonus\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Part 1\n",
    "\n",
    "You must submit:  \n",
    "- The **current notebook file** (`.ipynb`).  \n",
    "- Its **Python conversion** (`.py` file).  \n",
    "- The **Report** (`.pdf`).\n",
    "- Run **files** (`.txt`).\n",
    "\n",
    "All files should be placed inside a folder named \"RollNumber_PA1\". This folder must also include your **Part 2 files**, and the entire folder should be **zipped and submitted**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
